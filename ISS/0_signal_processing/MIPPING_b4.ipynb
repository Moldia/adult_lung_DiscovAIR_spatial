{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dir = r\"D:\\A52b_DISCOVAIR_R3\\Cycle 4\\2022_03_30_07_51_38--588B LNG2_Cycle 4_001/\"\n",
    "input_dir = input_dir.replace(\"\\\\\", \"/\")\n",
    "input_dir = input_dir.replace(\"\\\\\", \"/\")\n",
    "output_dir = 'D:\\Processing/588B_LNG2/'\n",
    "files = os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs =  [k for k in files if 'dw' not in k] # filter for deconvolved images\n",
    "tifs =  [k for k in tifs if '.tif' in k]\n",
    "tifs =  [k for k in tifs if '.txt' not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs =  [k for k in tifs if 'Corrected' in k]\n",
    "split_underscore = pd.DataFrame(tifs)[0].str.split('--', expand = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = [4]\n",
    "tiles = sorted(split_underscore[1].unique())\n",
    "channels = split_underscore[3].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage00\n",
      "Stage01\n",
      "Stage02\n",
      "Stage03\n",
      "Stage04\n",
      "Stage05\n",
      "Stage06\n",
      "Stage07\n",
      "Stage08\n",
      "Stage09\n",
      "Stage10\n",
      "Stage100\n",
      "Stage101\n",
      "Stage102\n",
      "Stage103\n",
      "Stage104\n",
      "Stage105\n",
      "Stage106\n",
      "Stage107\n",
      "Stage108\n",
      "Stage109\n",
      "Stage11\n",
      "Stage110\n",
      "Stage111\n",
      "Stage112\n",
      "Stage113\n",
      "Stage114\n",
      "Stage12\n",
      "Stage13\n",
      "Stage14\n",
      "Stage15\n",
      "Stage16\n",
      "Stage17\n",
      "Stage18\n",
      "Stage19\n",
      "Stage20\n",
      "Stage21\n",
      "Stage22\n",
      "Stage23\n",
      "Stage24\n",
      "Stage25\n",
      "Stage26\n",
      "Stage27\n",
      "Stage28\n",
      "Stage29\n",
      "Stage30\n",
      "Stage31\n",
      "Stage32\n",
      "Stage33\n",
      "Stage34\n",
      "Stage35\n",
      "Stage36\n",
      "Stage37\n",
      "Stage38\n",
      "Stage39\n",
      "Stage40\n",
      "Stage41\n",
      "Stage42\n",
      "Stage43\n",
      "Stage44\n",
      "Stage45\n",
      "Stage46\n",
      "Stage47\n",
      "Stage48\n",
      "Stage49\n",
      "Stage50\n",
      "Stage51\n",
      "Stage52\n",
      "Stage53\n",
      "Stage54\n",
      "Stage55\n",
      "Stage56\n",
      "Stage57\n",
      "Stage58\n",
      "Stage59\n",
      "Stage60\n",
      "Stage61\n",
      "Stage62\n",
      "Stage63\n",
      "Stage64\n",
      "Stage65\n",
      "Stage66\n",
      "Stage67\n",
      "Stage68\n",
      "Stage69\n",
      "Stage70\n",
      "Stage71\n",
      "Stage72\n",
      "Stage73\n",
      "Stage74\n",
      "Stage75\n",
      "Stage76\n",
      "Stage77\n",
      "Stage78\n",
      "Stage79\n",
      "Stage80\n",
      "Stage81\n",
      "Stage82\n",
      "Stage83\n",
      "Stage84\n",
      "Stage85\n",
      "Stage86\n",
      "Stage87\n",
      "Stage88\n",
      "Stage89\n",
      "Stage90\n",
      "Stage91\n",
      "Stage92\n",
      "Stage93\n",
      "Stage94\n",
      "Stage95\n",
      "Stage96\n",
      "Stage97\n",
      "Stage98\n",
      "Stage99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_output = output_dir + '/preprocessing/2DTiles/'\n",
    "if not os.path.exists(folder_output):\n",
    "    os.makedirs(folder_output)\n",
    "for 책책책, w in enumerate(sorted(bases)):\n",
    "    for f,i in enumerate(tiles):\n",
    "        print(i)\n",
    "        tifs_base_tile = [k for k in tifs if str(i)+'--' in k]\n",
    "        file_name = (folder_output+'Base_'+ str(int(w)) + '_t' + str(int(i.split('Stage')[1])+1) + '.tif')\n",
    "        if os.path.isfile(file_name)==True and os.path.getsize(file_name)>40000000:\n",
    "            print('already exists')\n",
    "        else:\n",
    "            with tifffile.TiffWriter(file_name) as stack:\n",
    "                for 책,z in enumerate(sorted(list(channels))):\n",
    "                    tifs_base_tile_channel = [k for k in tifs_base_tile if str(z) in k]\n",
    "                    maxi = np.zeros((2048,2048))\n",
    "                    for q in (tifs_base_tile_channel):\n",
    "                        im_array = imread(input_dir + q)\n",
    "                        inds = im_array > maxi # find where image intensity > max intensity\n",
    "                        maxi[inds] = im_array[inds]\n",
    "                    maxi = maxi.astype('uint16')\n",
    "                    stack.save(maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from xml.dom import minidom\n",
    "path = input_dir +  '/metadata/' \n",
    "metadatafiles = [n for n in os.listdir(path) if os.path.isfile(os.path.join(path,n))]\n",
    "metadatafiles_cleaned =  [k for k in metadatafiles if '.xlif' in k]\n",
    "output_dir_int=output_dir + '/preprocessing/2DTiles/'\n",
    "for p, meta in enumerate(metadatafiles_cleaned):\n",
    "    for base in range(5):\n",
    "            metadata_txt = open(output_dir_int +\"TileConfiguration_Base_\" + str(base+1) + \".txt\",\"a\") \n",
    "            metadata_txt.write('# Define the number of dimensions we are working on\\n')\n",
    "            metadata_txt.write('dim = 2\\n\\n# Define the image coordinates\\n')\n",
    "            mydoc = minidom.parse(path + meta)\n",
    "            tile =[]\n",
    "            x =[]\n",
    "            y =[]\n",
    "            items = mydoc.getElementsByTagName('Tile')\n",
    "            for elem in items:\n",
    "\n",
    "                tile.append(int(elem.attributes['FieldX'].value))\n",
    "                x.append(float(elem.attributes['PosX'].value))\n",
    "                y.append(float(elem.attributes['PosY'].value))\n",
    "\n",
    "\n",
    "            dict = {'x': x, 'y': y}     \n",
    "            df = pd.DataFrame(dict) \n",
    "            df['x'] =((df.x-np.min(df.x))/.000000321) + 1\n",
    "            df['y'] =((df.y-np.min(df.y))/.000000321) + 1\n",
    "\n",
    "            for elem in items:\n",
    "                tile_value = elem.attributes['FieldX'].value\n",
    "                x_value = ((float(elem.attributes['PosX'].value))-np.min(x))/.000000321 + 1\n",
    "                y_value = ((float(elem.attributes['PosY'].value))-np.min(y))/.000000321 + 1\n",
    "                metadata_txt.write('Base_' + str(base+1) + '_t' + tile_value +'; ; ' + '(' + str(x_value)+ ', ' + str(y_value) + ')' + '\\n')\n",
    "            df.to_csv(output_dir_int + 'tile_coordinates_Base_'+str(base+1)+'.csv', index = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpy",
   "language": "python",
   "name": "scanpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
